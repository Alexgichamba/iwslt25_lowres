{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2e_st.text.text_preprocessor import TranscriptionPreprocessor, TranslationPreprocessor\n",
    "import os\n",
    "import wget\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2e_st.text.tokenizer import CustomTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Register as a fast tokenizer in the second parameter\n",
    "AutoTokenizer.register(\"custom\", None, CustomTokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"alexgichamba/iwslt25_lowres_uncased_4096\", use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find vocab size\n",
    "vocab_size = tokenizer.vocab_size\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.bem_lang_token, tokenizer.eng_lang_token, tokenizer.fra_lang_token, tokenizer.fon_lang_token)\n",
    "print(tokenizer.bem_lang_token_id, tokenizer.eng_lang_token_id, tokenizer.fra_lang_token_id, tokenizer.fon_lang_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.tokenize(\"I shall also refer the matter to the College of Quaestors, and I am certain that they will be keen to ensure that we comply with the regulations we ourselves vote on.\".lower()))\n",
    "print(len(tokenizer.tokenize(\"I shall also refer the matter to the College of Quaestors, and I am certain that they will be keen to ensure that we comply with the regulations we ourselves vote on.\".lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.tokenize(\"Je vais soumettre également le problème au Collège des questeurs et je suis certaine que nos questeurs auront à cur de faire en sorte que nous respections la réglementation qu' en effet nous votons.\"))\n",
    "print(len(tokenizer.tokenize(\"Je vais soumettre également le problème au Collège des questeurs et je suis certaine que nos questeurs auront à cur de faire en sorte que nous respections la réglementation qu' en effet nous votons.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.tokenize(\"Ée yě ɖɔ mɔ̌ ɔ́, Mɔyízi lɛ́ kɔ bó yi ɖɔ nú Mawu Mavɔmavɔ ɖɔ: \\\"Aklúnɔ, étɛ́wú a wa nǔ xá togun élɔ́?\"))\n",
    "print(len(tokenizer.tokenize(\"Ée yě ɖɔ mɔ̌ ɔ́, Mɔyízi lɛ́ kɔ bó yi ɖɔ nú Mawu Mavɔmavɔ ɖɔ: \\\"Aklúnɔ, étɛ́wú a wa nǔ xá togun élɔ́?\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.tokenize(\"\\\"Pa kuti kasebanya naikila pali imwe, ali ne cipyu cickalamba, pa kwishibo kuti ali ne nshita inono fye.\\\" - Ukusokoloa 12:12.\"))\n",
    "print(len(tokenizer.tokenize(\"\\\"Pa kuti kasebanya naikila pali imwe, ali ne cipyu cickalamba, pa kwishibo kuti ali ne nshita inono fye.\\\" - Ukusokoloa 12:12.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_text_preprocessor():\n",
    "    token_types = [\"/ocean/projects/cis210027p/gichamba/iwslt25/iwslt25_lowres/iwslt25_lowres_cased_4096\"]\n",
    "    for token_type in token_types:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(token_type)\n",
    "        parallel_texts = [(\"I shall also refer the matter to the College of Quaestors, and I am certain that they will be keen to ensure that we comply with the regulations we ourselves vote on.\",\n",
    "                        \"Je vais soumettre également le problème au Collège des questeurs et je suis certaine que nos questeurs auront à cur de faire en sorte que nous respections la réglementation qu' en effet nous votons.\"),\n",
    "                            (\"Aya makampani yonse yaliile ku ntanshi no kucefyako incito no kufumyapo ababomfi.\", \"All these firms have gone ahead with job cuts and even redundancies.\"),\n",
    "                            (\"Mɛɖaxo, mi bi jlo na blo nuɖe bo na do fun ahwan xá adingban Elɔpu tɔn lɛ.\",\"Monsieur le Président, nous aimerions tous faire quelque chose pour aider à lutter contre la fraude en Europe.\"),\n",
    "                            (\"Mon travail a toujours dépassé la mode.\",\"Lelo umulimo wandi lyonse wali pa lwa fyacilapo ukucila pa fya kufwala.\")\n",
    "        ]\n",
    "        lang_pairs = [(\"eng\", \"fra\"), (\"bem\", \"eng\"), (\"fon\", \"fra\"), (\"fra\", \"bem\")]\n",
    "        transcripts = [\"We will build a wall\",\n",
    "                    \"\\\"Pa kuti kasebanya naikila pali imwe, ali ne cipyu cickalamba, pa kwishibo kuti ali ne nshita inono fye.\\\" - Ukusokoloa 12:12.\",\n",
    "                    \"Mɛni he je nɛ suɔmi nɛ ngɛ Mawu kɛ e Bi ɔ a kpɛti ɔ mi wa wawɛɛ ɔ?\",\n",
    "                    \"Moïse retourna vers l\\'Eternel, et dit: Seigneur, pourquoi as-tu fait du mal à ce peuple? pourquoi m\\'as-tu envoyé?...\"]\n",
    "        for i, (transcipt, parallel_text) in enumerate(zip(transcripts, parallel_texts)):  \n",
    "            transcription_preprocessor_upper = TranscriptionPreprocessor(case_standardization=\"upper\", tokenizer=tokenizer)\n",
    "            translation_preprocessor_upper = TranslationPreprocessor(case_standardization=\"upper\", tokenizer=tokenizer, source_language=lang_pairs[i][0], target_language=lang_pairs[i][1])\n",
    "            \n",
    "            transcription_preprocessor_lower = TranscriptionPreprocessor(tokenizer=tokenizer, case_standardization=\"lower\")\n",
    "            translation_preprocessor_lower = TranslationPreprocessor(case_standardization=\"lower\", tokenizer=tokenizer, source_language=lang_pairs[i][0], target_language=lang_pairs[i][1])\n",
    "\n",
    "            transcription_preprocessor_none = TranscriptionPreprocessor(tokenizer=tokenizer, case_standardization=None)\n",
    "            translation_preprocessor_none = TranslationPreprocessor(tokenizer = tokenizer, case_standardization=None, source_language=lang_pairs[i][0], target_language=lang_pairs[i][1])\n",
    "\n",
    "\n",
    "            print(f\"Original transcript: {transcipt}\")\n",
    "            print(f\"Upper case tokens: {tokenizer.tokenize(transcription_preprocessor_upper(transcipt))}\")\n",
    "            print(f\"Lower case tokens: {tokenizer.tokenize(transcription_preprocessor_lower(transcipt))}\")\n",
    "            print(f\"No case standardization transcript: {tokenizer.tokenize(transcription_preprocessor_none(transcipt))}\")\n",
    "            print(\"\\n\")\n",
    "            print(f\"Original translation: {parallel_text[0]} || {parallel_text[1]}\")\n",
    "            print(f\"Upper case translation: {tokenizer.tokenize(translation_preprocessor_upper(parallel_text[0], parallel_text[1]))}\")\n",
    "            print(f\"Lower case translation: {tokenizer.tokenize(translation_preprocessor_lower(parallel_text[0], parallel_text[1]))}\")\n",
    "            print(f\"No case standardization translation: {tokenizer.tokenize(translation_preprocessor_none(parallel_text[0], parallel_text[1]))}\")\n",
    "            print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
