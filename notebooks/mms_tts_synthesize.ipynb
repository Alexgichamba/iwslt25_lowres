{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "import torch\n",
        "from transformers import VitsModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "import json\n",
        "import os\n",
        "import gc"
      ],
      "metadata": {
        "id": "qpXW49NETBG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "\n",
        "os.environ['HF_TOKEN'] = HF_TOKEN"
      ],
      "metadata": {
        "id": "mONHIVASIOAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bemba synthesis"
      ],
      "metadata": {
        "id": "ziLYQWrrDEVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP3A31LuSD_X"
      },
      "outputs": [],
      "source": [
        "model = VitsModel.from_pretrained(\"facebook/mms-tts-bem\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-bem\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 bem_en.txt"
      ],
      "metadata": {
        "id": "MWNu4fCvDaFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"bem_en\"\n",
        "audio_path = f\"{base_path}/audio\"\n",
        "dataset_json = f\"{base_path}/bem_en.json\"\n",
        "os.makedirs(audio_path, exist_ok=True)\n",
        "os.system(f\"cp bem_en.txt {base_path}\")\n",
        "sample_rate = 16000\n",
        "dataset = []\n",
        "\n",
        "with open(\"bem_en.txt\", encoding=\"utf-8\") as f:\n",
        "    text = f.readlines()\n",
        "    for i, line in tqdm(enumerate(text), total=len(text)):\n",
        "        bem_sentence, en_sentence = line.split(\" || \")\n",
        "        bem_sentence = bem_sentence.strip()\n",
        "        en_sentence = en_sentence.strip()\n",
        "\n",
        "        inputs = tokenizer(bem_sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs).waveform\n",
        "\n",
        "        audio_numpy = output[0].cpu().numpy()\n",
        "\n",
        "        # Save with the correct 16kHz sampling rate\n",
        "        num_samples = len(audio_numpy)\n",
        "        # duration in seconds, rounded to milliseconds\n",
        "        duration = round(num_samples / sample_rate, 3)\n",
        "        audio_filename = f\"bem_{i}.wav\"\n",
        "        filename = f\"{audio_path}/{audio_filename}\"\n",
        "        sf.write(filename, audio_numpy, sample_rate)\n",
        "\n",
        "        # Add entry to dataset dictionary\n",
        "        entry = {\n",
        "            \"audio\": audio_filename,\n",
        "            \"duration_sec\": duration,\n",
        "            \"bem_transcript\": bem_sentence,\n",
        "            \"en_translation\": en_sentence\n",
        "        }\n",
        "\n",
        "        dataset.append(entry)\n",
        "\n",
        "# Dump all data to JSON file\n",
        "with open(dataset_json, 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(dataset, json_file, indent=4)"
      ],
      "metadata": {
        "id": "S903eWFyDgar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "6UyLNQMKobLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VitsModel.from_pretrained(\"facebook/mms-tts-fon\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-fon\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "mXVURrWKMfm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"fon_fr\"\n",
        "audio_path = f\"{base_path}/audio\"\n",
        "dataset_json = f\"{base_path}/fon_fr.json\"\n",
        "os.makedirs(audio_path, exist_ok=True)\n",
        "os.system(f\"cp fon_fr.txt {base_path}\")\n",
        "sample_rate = 16000\n",
        "dataset = []\n",
        "\n",
        "with open(\"fon_fr.txt\", encoding=\"utf-8\") as f:\n",
        "    text = f.readlines()\n",
        "    for i, line in tqdm(enumerate(text), total=len(text)):\n",
        "        fon_sentence, fr_sentence = line.split(\" || \")\n",
        "        fon_sentence = fon_sentence.strip()\n",
        "        fr_sentence = fr_sentence.strip()\n",
        "\n",
        "        inputs = tokenizer(fon_sentence, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(**inputs).waveform\n",
        "\n",
        "        audio_numpy = output[0].cpu().numpy()\n",
        "\n",
        "        # Save with the correct 16kHz sampling rate\n",
        "        num_samples = len(audio_numpy)\n",
        "        # duration in seconds, rounded to milliseconds\n",
        "        duration = round(num_samples / sample_rate, 3)\n",
        "        audio_filename = f\"fon_{i}.wav\"\n",
        "        filename = f\"{audio_path}/{audio_filename}\"\n",
        "        sf.write(filename, audio_numpy, sample_rate)\n",
        "\n",
        "        # Add entry to dataset dictionary\n",
        "        entry = {\n",
        "            \"audio\": audio_filename,\n",
        "            \"duration_sec\": duration,\n",
        "            \"fon_transcript\": fon_sentence,\n",
        "            \"fr_translation\": fr_sentence\n",
        "        }\n",
        "\n",
        "        dataset.append(entry)\n",
        "\n",
        "# Dump all data to JSON file\n",
        "with open(dataset_json, 'w', encoding='utf-8') as json_file:\n",
        "    json.dump(dataset, json_file, indent=4)"
      ],
      "metadata": {
        "id": "aB4GBLxXnUtT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}