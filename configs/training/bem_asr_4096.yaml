# Model configuration
model:
  name: "base"
  d_model: 512
  n_heads: 8
  d_ff: 2048
  n_enc_layers: 6
  n_dec_layers: 6
  enc_attn_dropout: 0.1
  dec_attn_dropout: 0.1
  speech_embedding_type: "whisper"
  ff_type: "swiglu"
  pe_max_len: 16384
  vocab_size: 4096
  dtype: "float16"
  
# Model checkpoint (optional)
# model_checkpoint: "checkpoints/pretrained_model.pt"

# Tokenizer path
tokenizer: "alexgichamba/iwslt25_uncased_4096"

# Task configuration
task: asr 
language: bem

# Audio configuration
audio:
  n_mels: 80
  hop_length: 320
  n_fft: 1280
  sample_rate: 16000

# Text configuration
text:
  case_standardization: "lower"

# Training configuration
training:
  batch_duration: 1800
  bucket_length_multiplier: 1.6
  validation_batch_size: 8
  num_epochs: 20
  learning_rate: 2.0e-4
  weight_decay: 0.001
  device: "cuda"
  mixed_precision: true
  num_workers: 4
  scheduler: "CosineAnnealingWarmupRestarts"
  warmup_steps: 100
  cycle_length: 4 # epochs
  min_lr: 1.0e-6
  label_smoothing: 0.1
  ctcloss_weight: 0.05
  max_decoding_length: 128
  use_sdpa: false

# Data configuration
data:
  root: "corpora"
  audio_root: "corpora/audio"

# Logging configuration
logging:
  log_interval: 100
  wandb: true
  wandb_project: "e2e_st"
  wandb_run_name: "bem_asr_small_4096"

# Output configuration
output:
  dir: "output/bem_asr_small_4096"